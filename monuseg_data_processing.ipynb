{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2888a642",
   "metadata": {},
   "source": [
    "# Make dataset Structure\n",
    "\n",
    "```\n",
    "monuseg_2018/\n",
    "├── images/\n",
    "│   ├── train/\n",
    "│   ├── val/\n",
    "│   └── test/         # optional\n",
    "├── labels/\n",
    "│   ├── train/\n",
    "│   ├── val/\n",
    "│   └── test/         # optional\n",
    "└── data.yaml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aaad415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[00mdata.yaml\u001b[0m\n",
      "├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mtest\u001b[0m\n",
      "│   ├── \u001b[01;34mtrain\u001b[0m\n",
      "│   └── \u001b[01;34mval\u001b[0m\n",
      "├── \u001b[01;34mlabels\u001b[0m\n",
      "│   ├── \u001b[01;34mtest\u001b[0m\n",
      "│   ├── \u001b[01;34mtrain\u001b[0m\n",
      "│   └── \u001b[01;34mval\u001b[0m\n",
      "└── \u001b[00mmonuseg_data_processing.ipynb\u001b[0m\n",
      "\n",
      "8 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "!mkdir images\n",
    "!mkdir images/train\n",
    "!mkdir images/val\n",
    "!mkdir images/test\n",
    "\n",
    "!mkdir labels\n",
    "!mkdir labels/train\n",
    "!mkdir labels/val\n",
    "!mkdir labels/test\n",
    "\n",
    "!touch data.yaml\n",
    "\n",
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d7b60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[01;34mannotations\u001b[0m\n",
      "│   ├── \u001b[01;34mtest\u001b[0m\n",
      "│   ├── \u001b[01;34mtrain\u001b[0m\n",
      "│   └── \u001b[01;34mval\u001b[0m\n",
      "├── \u001b[00mdata.yaml\u001b[0m\n",
      "├── \u001b[01;34mimages\u001b[0m\n",
      "│   ├── \u001b[01;34mtest\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-2Z-A9J9-01A-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-44-2665-01B-06-BS6.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-69-7764-01A-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-A6-6782-01A-01-BS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-AC-A2FO-01A-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-AO-A0J2-01A-01-BSA.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-CU-A0YN-01A-02-BSB.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-EJ-A46H-01A-03-TSC.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-FG-A4MU-01B-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-GL-6846-01A-01-BS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-HC-7209-01A-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-HT-8564-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;35mTCGA-IZ-8196-01A-01-BS1.tif\u001b[0m\n",
      "│   │   └── \u001b[01;35mTCGA-ZF-A9R5-01A-01-TS1.tif\u001b[0m\n",
      "│   ├── \u001b[01;34mtrain\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-18-5592-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-21-5784-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-21-5786-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-38-6178-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-49-4488-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-50-5931-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-A7-A13E-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-A7-A13F-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-AR-A1AK-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-AR-A1AS-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-AY-A8YK-01A-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-B0-5698-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-B0-5710-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-B0-5711-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-CH-5767-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-DK-A2I6-01A-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-E2-A14V-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-E2-A1B5-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-G2-A2EK-01A-02-TSB.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-G9-6336-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-G9-6348-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-G9-6356-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-G9-6362-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-G9-6363-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-HE-7128-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-HE-7129-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-HE-7130-01Z-00-DX1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-KB-A93J-01A-01-TS1.tif\u001b[0m\n",
      "│   │   ├── \u001b[01;32mTCGA-NH-A8F7-01A-01-TS1.tif\u001b[0m\n",
      "│   │   └── \u001b[01;32mTCGA-RD-A8N9-01A-01-TS1.tif\u001b[0m\n",
      "│   └── \u001b[01;34mval\u001b[0m\n",
      "│       ├── \u001b[01;32mTCGA-BC-A217-01Z-00-DX1.tif\u001b[0m\n",
      "│       ├── \u001b[01;32mTCGA-F9-A8NY-01Z-00-DX1.tif\u001b[0m\n",
      "│       ├── \u001b[01;32mTCGA-FG-A87N-01Z-00-DX1.tif\u001b[0m\n",
      "│       ├── \u001b[01;32mTCGA-MH-A561-01Z-00-DX1.tif\u001b[0m\n",
      "│       ├── \u001b[01;32mTCGA-UZ-A9PJ-01Z-00-DX1.tif\u001b[0m\n",
      "│       ├── \u001b[01;32mTCGA-UZ-A9PN-01Z-00-DX1.tif\u001b[0m\n",
      "│       └── \u001b[01;32mTCGA-XS-A8TJ-01Z-00-DX1.tif\u001b[0m\n",
      "├── \u001b[01;34mlabels\u001b[0m\n",
      "│   ├── \u001b[01;34mtest\u001b[0m\n",
      "│   ├── \u001b[01;34mtrain\u001b[0m\n",
      "│   └── \u001b[01;34mval\u001b[0m\n",
      "└── \u001b[00mmonuseg_data_processing.ipynb\u001b[0m\n",
      "\n",
      "12 directories, 53 files\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p annotations\n",
    "!mkdir -p annotations/train\n",
    "!mkdir -p annotations/val\n",
    "!mkdir -p annotations/test\n",
    "\n",
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc50e4",
   "metadata": {},
   "source": [
    "# Modify data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee996eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile data.yaml\n",
    "\n",
    "path: ../datasets/monuseg_2018  # or '.' if running from dataset dir\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 1  # number of classes\n",
    "names: ['nucleus']  # replace with your class name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193b3a5",
   "metadata": {},
   "source": [
    "# Copy images of train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4793290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: 37\n",
      "Validation Images: 7\n",
      "Test Images: 14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "train_image_dir = \"/home/mitun/Documents/thesis_oulu/datasets/MoNuseg 2018/train/Tissue Images\"\n",
    "train_xml_dir = \"/home/mitun/Documents/thesis_oulu/datasets/MoNuseg 2018/train/Annotations\"\n",
    "\n",
    "test_image_dir = \"/home/mitun/Documents/thesis_oulu/datasets/MoNuseg 2018/test\"\n",
    "test_xml_dir = \"/home/mitun/Documents/thesis_oulu/datasets/MoNuseg 2018/test\"\n",
    "\n",
    "new_train_image_dir = \"images/train\"\n",
    "new_val_image_dir = \"images/val\"\n",
    "new_test_image_dir = \"images/test\"\n",
    "\n",
    "new_train_xml_dir = \"annotations/train\"\n",
    "new_val_xml_dir = \"annotations/val\"\n",
    "new_test_xml_dir = \"annotations/test\"\n",
    "\n",
    "patient_ids = [\n",
    "    \"TCGA-A7-A13E\",\n",
    "    \"TCGA-A7-A13F\",\n",
    "    \"TCGA-AR-A1AK\",\n",
    "    \"TCGA-AR-A1AS\",\n",
    "    \"TCGA-E2-A1B5\",\n",
    "    \"TCGA-E2-A14V\",\n",
    "    \"TCGA-B0-5711\",\n",
    "    \"TCGA-HE-7128\",\n",
    "    \"TCGA-HE-7129\",\n",
    "    \"TCGA-HE-7130\",\n",
    "    \"TCGA-B0-5710\",\n",
    "    \"TCGA-B0-5698\",\n",
    "    \"TCGA-18-5592\",\n",
    "    \"TCGA-38-6178\",\n",
    "    \"TCGA-49-4488\",\n",
    "    \"TCGA-50-5931\",\n",
    "    \"TCGA-21-5784\",\n",
    "    \"TCGA-21-5786\",\n",
    "    \"TCGA-G9-6336\",\n",
    "    \"TCGA-G9-6348\",\n",
    "    \"TCGA-G9-6356\",\n",
    "    \"TCGA-G9-6363\",\n",
    "    \"TCGA-CH-5767\",\n",
    "    \"TCGA-G9-6362\",\n",
    "    \"TCGA-DK-A2I6\",\n",
    "    \"TCGA-G2-A2EK\",\n",
    "    \"TCGA-AY-A8YK\",\n",
    "    \"TCGA-NH-A8F7\",\n",
    "    \"TCGA-KB-A93J\",\n",
    "    \"TCGA-RD-A8N9\"\n",
    "]\n",
    "# copy train images\n",
    "train_images = os.listdir(train_image_dir)\n",
    "train_images = set(train_images)\n",
    "\n",
    "print(\"Train Images:\",len(train_images))\n",
    "    \n",
    "for patient_id in patient_ids:\n",
    "    # search for patient_id in train_image_dir\n",
    "    path = glob.glob(os.path.join(train_image_dir, f\"{patient_id}*.tif\"))\n",
    "\n",
    "    # get the file name\n",
    "    file_name = os.path.basename(path[0])\n",
    "\n",
    "    # remove the file name from the set of files\n",
    "    train_images.remove(file_name)\n",
    "\n",
    "    # copy the file to the new directory\n",
    "    shutil.copy(path[0], new_train_image_dir)\n",
    "    shutil.copy(os.path.join(train_xml_dir, file_name.replace(\".tif\", \".xml\")), new_train_xml_dir)\n",
    "\n",
    "print(\"Validation Images:\",len(train_images))\n",
    "# Copy rest of the files to the val directory\n",
    "for file in train_images:\n",
    "    shutil.copy(os.path.join(train_image_dir, file), new_val_image_dir)\n",
    "    shutil.copy(os.path.join(train_xml_dir, file.replace(\".tif\", \".xml\")), new_val_xml_dir)\n",
    "\n",
    "\n",
    "# copy test images\n",
    "test_images = glob.glob(os.path.join(test_image_dir, f\"*.tif\"))\n",
    "test_images = set(test_images)\n",
    "print(\"Test Images:\",len(test_images))\n",
    "for image_name in test_images:\n",
    "    shutil.copy(os.path.join(test_image_dir, image_name), new_test_image_dir)\n",
    "    shutil.copy(os.path.join(test_xml_dir, image_name.replace(\".tif\", \".xml\")), new_test_xml_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69839c6c",
   "metadata": {},
   "source": [
    "# Make Yolo labels from xml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import tv_tensors\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.v2 as T\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "class MoNuSegDataset(Dataset):\n",
    "    def __init__(self, image_dir, xml_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.xml_dir = xml_dir\n",
    "        self.transform = transform  # Adjust size as needed\n",
    "        \n",
    "        # Assumes matching filenames\n",
    "        self.image_names = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        xml_name = img_name.replace(\".tif\", \".xml\")  # adjust if needed\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        xml_path = os.path.join(self.xml_dir, xml_name)\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = tv_tensors.Image(image)\n",
    "        \n",
    "        \n",
    "        # Get contours from XML\n",
    "        contours = self.get_contours_from_xml(xml_path)\n",
    "        \n",
    "        # Create masks from contours\n",
    "        masks = np.array([self.contour_to_mask(contour, F.get_size(image)) for contour in contours])\n",
    "        masks = torch.tensor(masks)\n",
    "        \n",
    "        # Generate bounding boxes\n",
    "        boxes = torchvision.ops.masks_to_boxes(masks)\n",
    "        \n",
    "        # Generate bounding boxes from contours\n",
    "        labels = torch.ones(len(boxes), dtype=torch.int64)\n",
    "\n",
    "        # Define the target dictionary\n",
    "        target = {}\n",
    "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(image))   # dtype=torch.int64\n",
    "        target[\"masks\"] = tv_tensors.Mask(masks)   # dtype=torch.uint8\n",
    "        target[\"labels\"] = labels # dtype=torch.int64\n",
    "        \n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image, target = self.transform(image, target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    @staticmethod\n",
    "    def get_contours_from_xml(xml_file):\n",
    "        \"\"\"\n",
    "        Parses an XML annotation file and extracts region vertices.\n",
    "\n",
    "        Args:\n",
    "            xml_file (str): Path to the annotation XML file.\n",
    "\n",
    "        Returns:\n",
    "            list of numpy.ndarray: Each array is of shape (n_points, 2),\n",
    "            containing (x, y) coordinates of one annotated region.\n",
    "        \"\"\"\n",
    "        xy = []\n",
    "        try:\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            regions = root.findall('.//Annotation/Regions/Region')\n",
    "\n",
    "            for region in regions:\n",
    "                vertices = region.findall('./Vertices/Vertex')\n",
    "                coords = [(float(v.get('X')), float(v.get('Y'))) for v in vertices]\n",
    "                if coords:\n",
    "                    xy.append(np.array(coords, dtype=np.int32))\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: XML file not found: {xml_file}\")\n",
    "            return []\n",
    "        except ET.ParseError:\n",
    "            print(f\"Error: Could not parse XML file: {xml_file}\")\n",
    "            return []\n",
    "\n",
    "        return xy\n",
    "\n",
    "    @staticmethod    \n",
    "    def contour_to_mask(contour, mask_size):\n",
    "        \"\"\"\n",
    "        Converts a contour (polygon) to a binary mask.\n",
    "\n",
    "        Args:\n",
    "            contour (numpy.ndarray): List of (x, y) vertices defining the contour.\n",
    "            mask_size (tuple): Size of the output mask (height, width).\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Binary mask with the contour filled.\n",
    "        \"\"\"\n",
    "        mask = np.zeros(mask_size, dtype=np.uint8)\n",
    "        cv2.fillPoly(mask, [np.array(contour, dtype=np.int32)], 1)\n",
    "        return mask\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = MoNuSegDataset(image_dir=new_train_image_dir, xml_dir=new_train_xml_dir)\n",
    "val_dataset = MoNuSegDataset(image_dir=new_val_image_dir, xml_dir=new_val_xml_dir)\n",
    "test_dataset = MoNuSegDataset(image_dir=new_test_image_dir, xml_dir=new_test_xml_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
